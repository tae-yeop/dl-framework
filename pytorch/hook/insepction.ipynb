{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass 중에 shape알기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the intermediate tensor is: torch.Size([1, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define a hook function to print the shape of the intermediate tensor\n",
    "def print_tensor_shape(module, input, output):\n",
    "    print(f\"The shape of the intermediate tensor is: {output.shape}\")\n",
    "\n",
    "# Define the neural network architecture\n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(10, 20)\n",
    "        self.fc2 = torch.nn.Linear(20, 30)\n",
    "        self.fc3 = torch.nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "net = MyNet()\n",
    "\n",
    "# Register the hook on a specific layer\n",
    "hook_handle = net.fc2.register_forward_hook(print_tensor_shape)\n",
    "\n",
    "# Generate some random input\n",
    "x = torch.randn(1, 10)\n",
    "\n",
    "# Pass the input through the network\n",
    "output = net(x)\n",
    "\n",
    "# Remove the hook\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--name\", default=\"test\")\n",
    "    parser.add_argument(\"--gpu_ids\", default=\"\")\n",
    "    parser.add_argument('-j', '--workers', type=int, default=4)\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=8)\n",
    "    parser.add_argument('--fp16', action='store_true', help='use amp')\n",
    "\n",
    "    parser.add_argument(\"--dataroot\", default=\"./data/\")\n",
    "    parser.add_argument(\"--datamode\", default=\"train\")\n",
    "    parser.add_argument(\"--data_list\", default=\"train_pairs.txt\")\n",
    "    parser.add_argument(\"--fine_width\", type=int, default=192)\n",
    "    parser.add_argument(\"--fine_height\", type=int, default=256)\n",
    "\n",
    "    parser.add_argument('--tensorboard_dir', type=str, default='tensorboard', help='save tensorboard infos')\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints', help='save checkpoint infos')\n",
    "    parser.add_argument('--tocg_checkpoint', type=str, default='', help='tocg checkpoint')\n",
    "\n",
    "    parser.add_argument(\"--tensorboard_count\", type=int, default=100)\n",
    "    parser.add_argument(\"--display_count\", type=int, default=100)\n",
    "    parser.add_argument(\"--save_count\", type=int, default=10000)\n",
    "    parser.add_argument(\"--load_step\", type=int, default=0)\n",
    "    parser.add_argument(\"--keep_step\", type=int, default=300000)\n",
    "    parser.add_argument(\"--shuffle\", action='store_true', help='shuffle input data')\n",
    "    parser.add_argument(\"--semantic_nc\", type=int, default=13)\n",
    "    parser.add_argument(\"--output_nc\", type=int, default=13)\n",
    "    \n",
    "    # network\n",
    "    parser.add_argument(\"--warp_feature\", choices=['encoder', 'T1'], default=\"T1\")\n",
    "    parser.add_argument(\"--out_layer\", choices=['relu', 'conv'], default=\"relu\")\n",
    "    parser.add_argument('--Ddownx2', action='store_true', help=\"Downsample D's input to increase the receptive field\")  \n",
    "    parser.add_argument('--Ddropout', action='store_true', help=\"Apply dropout to D\")\n",
    "    parser.add_argument('--num_D', type=int, default=2, help='Generator ngf')\n",
    "    # Cuda availability\n",
    "    parser.add_argument('--cuda',default=False, help='cuda or cpu')\n",
    "    # training\n",
    "    parser.add_argument(\"--G_D_seperate\", action='store_true')\n",
    "    parser.add_argument(\"--no_GAN_loss\", action='store_true')\n",
    "    parser.add_argument(\"--lasttvonly\", action='store_true')\n",
    "    parser.add_argument(\"--interflowloss\", action='store_true', help=\"Intermediate flow loss\")\n",
    "    parser.add_argument(\"--clothmask_composition\", type=str, choices=['no_composition', 'detach', 'warp_grad'], default='warp_grad')\n",
    "    parser.add_argument('--edgeawaretv', type=str, choices=['no_edge', 'last_only', 'weighted'], default=\"no_edge\", help=\"Edge aware TV loss\")\n",
    "    parser.add_argument('--add_lasttv', action='store_true')\n",
    "    \n",
    "    # test visualize\n",
    "    parser.add_argument(\"--no_test_visualize\", action='store_true')    \n",
    "    parser.add_argument(\"--num_test_visualize\", type=int, default=3)\n",
    "    parser.add_argument(\"--test_datasetting\", default=\"unpaired\")\n",
    "    parser.add_argument(\"--test_dataroot\", default=\"./data/\")\n",
    "    parser.add_argument(\"--test_data_list\", default=\"test_pairs.txt\")\n",
    "    \n",
    "\n",
    "    # Hyper-parameters\n",
    "    parser.add_argument('--G_lr', type=float, default=0.0002, help='Generator initial learning rate for adam')\n",
    "    parser.add_argument('--D_lr', type=float, default=0.0002, help='Discriminator initial learning rate for adam')\n",
    "    parser.add_argument('--CElamda', type=float, default=10, help='initial learning rate for adam')\n",
    "    parser.add_argument('--GANlambda', type=float, default=1)\n",
    "    parser.add_argument('--tvlambda', type=float, default=2)\n",
    "    parser.add_argument('--upsample', type=str, default='bilinear', choices=['nearest', 'bilinear'])\n",
    "    parser.add_argument('--val_count', type=int, default='1000')\n",
    "    parser.add_argument('--spectral', action='store_true', help=\"Apply spectral normalization to D\")\n",
    "    parser.add_argument('--occlusion', action='store_true', help=\"Occlusion handling\")\n",
    "\n",
    "    # opt = parser.parse_args()\n",
    "    opt = parser.parse_args(args=[])\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionGenerator(nn.Module):\n",
    "    def __init__(self, opt, input1_nc, input2_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d):\n",
    "        super(ConditionGenerator, self).__init__()\n",
    "        self.warp_feature = opt.warp_feature\n",
    "        self.out_layer_opt = opt.out_layer\n",
    "        \n",
    "        self.ClothEncoder = nn.Sequential(\n",
    "            ResBlock(input1_nc, ngf, norm_layer=norm_layer, scale='down'),  # 128\n",
    "            ResBlock(ngf, ngf * 2, norm_layer=norm_layer, scale='down'),  # 64\n",
    "            ResBlock(ngf * 2, ngf * 4, norm_layer=norm_layer, scale='down'),  # 32\n",
    "            ResBlock(ngf * 4, ngf * 4, norm_layer=norm_layer, scale='down'),  # 16\n",
    "            ResBlock(ngf * 4, ngf * 4, norm_layer=norm_layer, scale='down')  # 8\n",
    "        )\n",
    "        \n",
    "        self.PoseEncoder = nn.Sequential(\n",
    "            ResBlock(input2_nc, ngf, norm_layer=norm_layer, scale='down'),\n",
    "            ResBlock(ngf, ngf * 2, norm_layer=norm_layer, scale='down'),\n",
    "            ResBlock(ngf * 2, ngf * 4, norm_layer=norm_layer, scale='down'),\n",
    "            ResBlock(ngf * 4, ngf * 4, norm_layer=norm_layer, scale='down'),\n",
    "            ResBlock(ngf * 4, ngf * 4, norm_layer=norm_layer, scale='down')\n",
    "        )\n",
    "        \n",
    "        self.conv = ResBlock(ngf * 4, ngf * 8, norm_layer=norm_layer, scale='same')\n",
    "        \n",
    "        if opt.warp_feature == 'T1':\n",
    "            # in_nc -> skip connection + T1, T2 channel\n",
    "            self.SegDecoder = nn.Sequential(\n",
    "                ResBlock(ngf * 8, ngf * 4, norm_layer=norm_layer, scale='up'),  # 16\n",
    "                ResBlock(ngf * 4 * 2 + ngf * 4 , ngf * 4, norm_layer=norm_layer, scale='up'),  # 32\n",
    "                ResBlock(ngf * 4 * 2 + ngf * 4 , ngf * 2, norm_layer=norm_layer, scale='up'),  # 64\n",
    "                ResBlock(ngf * 2 * 2 + ngf * 4 , ngf, norm_layer=norm_layer, scale='up'),  # 128\n",
    "                ResBlock(ngf * 1 * 2 + ngf * 4, ngf, norm_layer=norm_layer, scale='up')  # 256\n",
    "            )\n",
    "        if opt.warp_feature == 'encoder':\n",
    "            # in_nc -> [x, skip_connection, warped_cloth_encoder_feature(E1)]\n",
    "            self.SegDecoder = nn.Sequential(\n",
    "                ResBlock(ngf * 8, ngf * 4, norm_layer=norm_layer, scale='up'),  # 16\n",
    "                ResBlock(ngf * 4 * 3, ngf * 4, norm_layer=norm_layer, scale='up'),  # 32\n",
    "                ResBlock(ngf * 4 * 3, ngf * 2, norm_layer=norm_layer, scale='up'),  # 64\n",
    "                ResBlock(ngf * 2 * 3, ngf, norm_layer=norm_layer, scale='up'),  # 128\n",
    "                ResBlock(ngf * 1 * 3, ngf, norm_layer=norm_layer, scale='up')  # 256\n",
    "            )\n",
    "        if opt.out_layer == 'relu':\n",
    "            self.out_layer = ResBlock(ngf + input1_nc + input2_nc, output_nc, norm_layer=norm_layer, scale='same')\n",
    "        if opt.out_layer == 'conv':\n",
    "            self.out_layer = nn.Sequential(\n",
    "                ResBlock(ngf + input1_nc + input2_nc, ngf, norm_layer=norm_layer, scale='same'),\n",
    "                nn.Conv2d(ngf, output_nc, kernel_size=1, bias=True)\n",
    "            )\n",
    "        \n",
    "        # Cloth Conv 1x1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(ngf, ngf * 4, kernel_size=1, bias=True),\n",
    "            nn.Conv2d(ngf * 2, ngf * 4, kernel_size=1, bias=True),\n",
    "            nn.Conv2d(ngf * 4, ngf * 4, kernel_size=1, bias=True),\n",
    "            nn.Conv2d(ngf * 4, ngf * 4, kernel_size=1, bias=True),\n",
    "        )\n",
    "\n",
    "        # Person Conv 1x1\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ngf, ngf * 4, kernel_size=1, bias=True),\n",
    "            nn.Conv2d(ngf * 2, ngf * 4, kernel_size=1, bias=True),\n",
    "            nn.Conv2d(ngf * 4, ngf * 4, kernel_size=1, bias=True),\n",
    "            nn.Conv2d(ngf * 4, ngf * 4, kernel_size=1, bias=True),\n",
    "        )\n",
    "        \n",
    "        self.flow_conv = nn.ModuleList([\n",
    "            nn.Conv2d(ngf * 8, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.Conv2d(ngf * 8, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.Conv2d(ngf * 8, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.Conv2d(ngf * 8, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.Conv2d(ngf * 8, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Sequential(nn.Conv2d(ngf * 4, ngf * 4, kernel_size=3, stride=1, padding=1, bias=True), nn.ReLU()),\n",
    "            nn.Sequential(nn.Conv2d(ngf * 4, ngf * 4, kernel_size=3, stride=1, padding=1, bias=True), nn.ReLU()),\n",
    "            nn.Sequential(nn.Conv2d(ngf * 2, ngf * 4, kernel_size=3, stride=1, padding=1, bias=True) , nn.ReLU()),\n",
    "            nn.Sequential(nn.Conv2d(ngf, ngf * 4, kernel_size=3, stride=1, padding=1, bias=True), nn.ReLU()),\n",
    "        )\n",
    "        \n",
    "    def normalize(self, x):\n",
    "        return x\n",
    "    \n",
    "    def forward(self,opt,input1, input2, upsample='bilinear'):\n",
    "        E1_list = []\n",
    "        E2_list = []\n",
    "        flow_list = []\n",
    "        # warped_grid_list = []\n",
    "\n",
    "        # Feature Pyramid Network\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                E1_list.append(self.ClothEncoder[i](input1))\n",
    "                E2_list.append(self.PoseEncoder[i](input2))\n",
    "            else:\n",
    "                E1_list.append(self.ClothEncoder[i](E1_list[i - 1]))\n",
    "                E2_list.append(self.PoseEncoder[i](E2_list[i - 1]))\n",
    "\n",
    "        # Compute Clothflow\n",
    "        for i in range(5):\n",
    "            N, _, iH, iW = E1_list[4 - i].size()\n",
    "            grid = make_grid(N, iH, iW,opt)\n",
    "\n",
    "            if i == 0:\n",
    "                T1 = E1_list[4 - i]  # (ngf * 4) x 8 x 6\n",
    "                T2 = E2_list[4 - i]\n",
    "                E4 = torch.cat([T1, T2], 1)\n",
    "                \n",
    "                flow = self.flow_conv[i](self.normalize(E4)).permute(0, 2, 3, 1)\n",
    "                flow_list.append(flow)\n",
    "                \n",
    "                x = self.conv(T2)\n",
    "                x = self.SegDecoder[i](x)\n",
    "                \n",
    "            else:\n",
    "                T1 = F.interpolate(T1, scale_factor=2, mode=upsample) + self.conv1[4 - i](E1_list[4 - i])\n",
    "                T2 = F.interpolate(T2, scale_factor=2, mode=upsample) + self.conv2[4 - i](E2_list[4 - i]) \n",
    "                \n",
    "                flow = F.interpolate(flow_list[i - 1].permute(0, 3, 1, 2), scale_factor=2, mode=upsample).permute(0, 2, 3, 1)  # upsample n-1 flow\n",
    "                flow_norm = torch.cat([flow[:, :, :, 0:1] / ((iW/2 - 1.0) / 2.0), flow[:, :, :, 1:2] / ((iH/2 - 1.0) / 2.0)], 3)\n",
    "                warped_T1 = F.grid_sample(T1, flow_norm + grid, padding_mode='border')\n",
    "                \n",
    "                flow = flow + self.flow_conv[i](self.normalize(torch.cat([warped_T1, self.bottleneck[i-1](x)], 1))).permute(0, 2, 3, 1)  # F(n)\n",
    "                flow_list.append(flow)\n",
    "\n",
    "                if self.warp_feature == 'T1':\n",
    "                    x = self.SegDecoder[i](torch.cat([x, E2_list[4-i], warped_T1], 1))\n",
    "                if self.warp_feature == 'encoder':\n",
    "                    warped_E1 = F.grid_sample(E1_list[4-i], flow_norm + grid, padding_mode='border')\n",
    "                    x = self.SegDecoder[i](torch.cat([x, E2_list[4-i], warped_E1], 1))\n",
    "        \n",
    " \n",
    "        N, _, iH, iW = input1.size()\n",
    "        grid = make_grid(N, iH, iW,opt)\n",
    "        \n",
    "        flow = F.interpolate(flow_list[-1].permute(0, 3, 1, 2), scale_factor=2, mode=upsample).permute(0, 2, 3, 1)\n",
    "        flow_norm = torch.cat([flow[:, :, :, 0:1] / ((iW/2 - 1.0) / 2.0), flow[:, :, :, 1:2] / ((iH/2 - 1.0) / 2.0)], 3)\n",
    "        warped_input1 = F.grid_sample(input1, flow_norm + grid, padding_mode='border')\n",
    "        \n",
    "        x = self.out_layer(torch.cat([x, input2, warped_input1], 1))\n",
    "\n",
    "        warped_c = warped_input1[:, :-1, :, :]\n",
    "        warped_cm = warped_input1[:, -1:, :, :]\n",
    "\n",
    "        return flow_list, x, warped_c, warped_cm\n",
    "\n",
    "def make_grid(N, iH, iW,opt):\n",
    "    grid_x = torch.linspace(-1.0, 1.0, iW).view(1, 1, iW, 1).expand(N, iH, -1, -1)\n",
    "    grid_y = torch.linspace(-1.0, 1.0, iH).view(1, iH, 1, 1).expand(N, -1, iW, -1)\n",
    "    if opt.cuda :\n",
    "        grid = torch.cat([grid_x, grid_y], 3).cuda()\n",
    "    else:\n",
    "        grid = torch.cat([grid_x, grid_y], 3)\n",
    "    return grid\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, scale='down', norm_layer=nn.BatchNorm2d):\n",
    "        super(ResBlock, self).__init__()\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        assert scale in ['up', 'down', 'same'], \"ResBlock scale must be in 'up' 'down' 'same'\"\n",
    "\n",
    "        if scale == 'same':\n",
    "            self.scale = nn.Conv2d(in_nc, out_nc, kernel_size=1, bias=True)\n",
    "        if scale == 'up':\n",
    "            self.scale = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                nn.Conv2d(in_nc, out_nc, kernel_size=1,bias=True)\n",
    "            )\n",
    "        if scale == 'down':\n",
    "            self.scale = nn.Conv2d(in_nc, out_nc, kernel_size=3, stride=2, padding=1, bias=use_bias)\n",
    "            \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(out_nc, out_nc, kernel_size=3, stride=1, padding=1, bias=use_bias),\n",
    "            norm_layer(out_nc),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_nc, out_nc, kernel_size=3, stride=1, padding=1, bias=use_bias),\n",
    "            norm_layer(out_nc)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.scale(x)\n",
    "        return self.relu(residual + self.block(residual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = get_opt()\n",
    "\n",
    "input1_nc = 4  # cloth + cloth-mask\n",
    "input2_nc = opt.semantic_nc + 3\n",
    "output_nc = opt.output_nc\n",
    "\n",
    "input1 = torch.randn(1, input1_nc, 256, 128)\n",
    "input2 = torch.randn(1, input2_nc, 256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.0.scale\n",
      "Input shape: torch.Size([1, 4, 256, 128])\n",
      "ClothEncoder.0.scale output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.0.block.0\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.block.0 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.0.block.1\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.block.1 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.0.block.2\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.block.2 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.0.block.3\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.block.3 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.0.block.4\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.block.4 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: ClothEncoder.0.block\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.block output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.0.relu\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.0.relu output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: ClothEncoder.0\n",
      "Input shape: torch.Size([1, 4, 256, 128])\n",
      "ClothEncoder.0 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.0.scale\n",
      "Input shape: torch.Size([1, 16, 256, 128])\n",
      "PoseEncoder.0.scale output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.0.block.0\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.block.0 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.0.block.1\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.block.1 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.0.block.2\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.block.2 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.0.block.3\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.block.3 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.0.block.4\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.block.4 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: PoseEncoder.0.block\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.block output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.0.relu\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.0.relu output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: PoseEncoder.0\n",
      "Input shape: torch.Size([1, 16, 256, 128])\n",
      "PoseEncoder.0 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.1.scale\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.1.scale output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.1.block.0\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.block.0 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.1.block.1\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.block.1 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.1.block.2\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.block.2 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.1.block.3\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.block.3 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.1.block.4\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.block.4 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: ClothEncoder.1.block\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.block output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.1.relu\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.1.relu output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: ClothEncoder.1\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "ClothEncoder.1 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.1.scale\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.1.scale output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.1.block.0\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.block.0 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.1.block.1\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.block.1 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.1.block.2\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.block.2 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.1.block.3\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.block.3 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.1.block.4\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.block.4 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: PoseEncoder.1.block\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.block output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.1.relu\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.1.relu output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: PoseEncoder.1\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "PoseEncoder.1 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.2.scale\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.2.scale output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.2.block.0\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.block.0 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.2.block.1\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.block.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.2.block.2\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.block.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.2.block.3\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.block.3 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.2.block.4\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.block.4 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: ClothEncoder.2.block\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.block output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.2.relu\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.2.relu output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: ClothEncoder.2\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "ClothEncoder.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.2.scale\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.2.scale output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.2.block.0\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.block.0 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.2.block.1\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.block.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.2.block.2\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.block.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.2.block.3\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.block.3 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.2.block.4\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.block.4 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: PoseEncoder.2.block\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.block output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.2.relu\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.2.relu output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: PoseEncoder.2\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "PoseEncoder.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.3.scale\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.3.scale output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.3.block.0\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.block.0 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.3.block.1\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.block.1 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.3.block.2\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.block.2 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.3.block.3\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.block.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.3.block.4\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.block.4 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: ClothEncoder.3.block\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.block output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.3.relu\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.3.relu output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: ClothEncoder.3\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "ClothEncoder.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.3.scale\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.3.scale output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.3.block.0\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.block.0 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.3.block.1\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.block.1 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.3.block.2\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.block.2 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.3.block.3\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.block.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.3.block.4\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.block.4 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: PoseEncoder.3.block\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.block output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.3.relu\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.3.relu output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: PoseEncoder.3\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "PoseEncoder.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.4.scale\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.4.scale output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.4.block.0\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.block.0 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.4.block.1\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.block.1 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.4.block.2\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.block.2 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: ClothEncoder.4.block.3\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.block.3 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: ClothEncoder.4.block.4\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.block.4 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: ClothEncoder.4.block\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.block output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: ClothEncoder.4.relu\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "ClothEncoder.4.relu output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: ClothEncoder.4\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "ClothEncoder.4 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.4.scale\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.4.scale output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.4.block.0\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.block.0 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.4.block.1\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.block.1 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.4.block.2\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.block.2 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: PoseEncoder.4.block.3\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.block.3 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: PoseEncoder.4.block.4\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.block.4 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: PoseEncoder.4.block\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.block output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: PoseEncoder.4.relu\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "PoseEncoder.4.relu output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: PoseEncoder.4\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "PoseEncoder.4 output shape: torch.Size([1, 256, 8, 4])\n",
      "\n",
      "Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: flow_conv.0\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "flow_conv.0 output shape: torch.Size([1, 2, 8, 4])\n",
      "\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv.scale\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "conv.scale output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv.block.0\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.block.0 output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: conv.block.1\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.block.1 output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: conv.block.2\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.block.2 output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv.block.3\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.block.3 output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: conv.block.4\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.block.4 output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: conv.block\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.block output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: conv.relu\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "conv.relu output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: conv\n",
      "Input shape: torch.Size([1, 256, 8, 4])\n",
      "conv output shape: torch.Size([1, 512, 8, 4])\n",
      "\n",
      "Upsample(scale_factor=2.0, mode=bilinear)\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "Module Name: SegDecoder.0.scale.0\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "SegDecoder.0.scale.0 output shape: torch.Size([1, 512, 16, 8])\n",
      "\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.0.scale.1\n",
      "Input shape: torch.Size([1, 512, 16, 8])\n",
      "SegDecoder.0.scale.1 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Sequential(\n",
      "  (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.0.scale\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "SegDecoder.0.scale output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.0.block.0\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.block.0 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.0.block.1\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.block.1 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.0.block.2\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.block.2 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.0.block.3\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.block.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.0.block.4\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.block.4 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.0.block\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.block output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.0.relu\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "SegDecoder.0.relu output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: SegDecoder.0\n",
      "Input shape: torch.Size([1, 512, 8, 4])\n",
      "SegDecoder.0 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv1.3\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "conv1.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv2.3\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "conv2.3 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: bottleneck.0.0\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "bottleneck.0.0 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "ReLU()\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: bottleneck.0.1\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "bottleneck.0.1 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: bottleneck.0\n",
      "Input shape: torch.Size([1, 256, 16, 8])\n",
      "bottleneck.0 output shape: torch.Size([1, 256, 16, 8])\n",
      "\n",
      "Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: flow_conv.1\n",
      "Input shape: torch.Size([1, 512, 16, 8])\n",
      "flow_conv.1 output shape: torch.Size([1, 2, 16, 8])\n",
      "\n",
      "Upsample(scale_factor=2.0, mode=bilinear)\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "Module Name: SegDecoder.1.scale.0\n",
      "Input shape: torch.Size([1, 768, 16, 8])\n",
      "SegDecoder.1.scale.0 output shape: torch.Size([1, 768, 32, 16])\n",
      "\n",
      "Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.1.scale.1\n",
      "Input shape: torch.Size([1, 768, 32, 16])\n",
      "SegDecoder.1.scale.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Sequential(\n",
      "  (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (1): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.1.scale\n",
      "Input shape: torch.Size([1, 768, 16, 8])\n",
      "SegDecoder.1.scale output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.1.block.0\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.block.0 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.1.block.1\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.block.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.1.block.2\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.block.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.1.block.3\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.block.3 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.1.block.4\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.block.4 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.1.block\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.block output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.1.relu\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "SegDecoder.1.relu output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: SegDecoder.1\n",
      "Input shape: torch.Size([1, 768, 16, 8])\n",
      "SegDecoder.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv1.2\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "conv1.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv2.2\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "conv2.2 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: bottleneck.1.0\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "bottleneck.1.0 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "ReLU()\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: bottleneck.1.1\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "bottleneck.1.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: bottleneck.1\n",
      "Input shape: torch.Size([1, 256, 32, 16])\n",
      "bottleneck.1 output shape: torch.Size([1, 256, 32, 16])\n",
      "\n",
      "Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: flow_conv.2\n",
      "Input shape: torch.Size([1, 512, 32, 16])\n",
      "flow_conv.2 output shape: torch.Size([1, 2, 32, 16])\n",
      "\n",
      "Upsample(scale_factor=2.0, mode=bilinear)\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "Module Name: SegDecoder.2.scale.0\n",
      "Input shape: torch.Size([1, 768, 32, 16])\n",
      "SegDecoder.2.scale.0 output shape: torch.Size([1, 768, 64, 32])\n",
      "\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.2.scale.1\n",
      "Input shape: torch.Size([1, 768, 64, 32])\n",
      "SegDecoder.2.scale.1 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Sequential(\n",
      "  (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.2.scale\n",
      "Input shape: torch.Size([1, 768, 32, 16])\n",
      "SegDecoder.2.scale output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.2.block.0\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.block.0 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.2.block.1\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.block.1 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.2.block.2\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.block.2 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.2.block.3\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.block.3 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.2.block.4\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.block.4 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.2.block\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.block output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.2.relu\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "SegDecoder.2.relu output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: SegDecoder.2\n",
      "Input shape: torch.Size([1, 768, 32, 16])\n",
      "SegDecoder.2 output shape: torch.Size([1, 128, 64, 32])\n",
      "\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv1.1\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "conv1.1 output shape: torch.Size([1, 256, 64, 32])\n",
      "\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv2.1\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "conv2.1 output shape: torch.Size([1, 256, 64, 32])\n",
      "\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: bottleneck.2.0\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "bottleneck.2.0 output shape: torch.Size([1, 256, 64, 32])\n",
      "\n",
      "ReLU()\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: bottleneck.2.1\n",
      "Input shape: torch.Size([1, 256, 64, 32])\n",
      "bottleneck.2.1 output shape: torch.Size([1, 256, 64, 32])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: bottleneck.2\n",
      "Input shape: torch.Size([1, 128, 64, 32])\n",
      "bottleneck.2 output shape: torch.Size([1, 256, 64, 32])\n",
      "\n",
      "Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: flow_conv.3\n",
      "Input shape: torch.Size([1, 512, 64, 32])\n",
      "flow_conv.3 output shape: torch.Size([1, 2, 64, 32])\n",
      "\n",
      "Upsample(scale_factor=2.0, mode=bilinear)\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "Module Name: SegDecoder.3.scale.0\n",
      "Input shape: torch.Size([1, 512, 64, 32])\n",
      "SegDecoder.3.scale.0 output shape: torch.Size([1, 512, 128, 64])\n",
      "\n",
      "Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.3.scale.1\n",
      "Input shape: torch.Size([1, 512, 128, 64])\n",
      "SegDecoder.3.scale.1 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Sequential(\n",
      "  (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.3.scale\n",
      "Input shape: torch.Size([1, 512, 64, 32])\n",
      "SegDecoder.3.scale output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.3.block.0\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.block.0 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.3.block.1\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.block.1 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.3.block.2\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.block.2 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.3.block.3\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.block.3 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.3.block.4\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.block.4 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.3.block\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.block output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.3.relu\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "SegDecoder.3.relu output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: SegDecoder.3\n",
      "Input shape: torch.Size([1, 512, 64, 32])\n",
      "SegDecoder.3 output shape: torch.Size([1, 64, 128, 64])\n",
      "\n",
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv1.0\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "conv1.0 output shape: torch.Size([1, 256, 128, 64])\n",
      "\n",
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: conv2.0\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "conv2.0 output shape: torch.Size([1, 256, 128, 64])\n",
      "\n",
      "Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: bottleneck.3.0\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "bottleneck.3.0 output shape: torch.Size([1, 256, 128, 64])\n",
      "\n",
      "ReLU()\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: bottleneck.3.1\n",
      "Input shape: torch.Size([1, 256, 128, 64])\n",
      "bottleneck.3.1 output shape: torch.Size([1, 256, 128, 64])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: bottleneck.3\n",
      "Input shape: torch.Size([1, 64, 128, 64])\n",
      "bottleneck.3 output shape: torch.Size([1, 256, 128, 64])\n",
      "\n",
      "Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: flow_conv.4\n",
      "Input shape: torch.Size([1, 512, 128, 64])\n",
      "flow_conv.4 output shape: torch.Size([1, 2, 128, 64])\n",
      "\n",
      "Upsample(scale_factor=2.0, mode=bilinear)\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "Module Name: SegDecoder.4.scale.0\n",
      "Input shape: torch.Size([1, 384, 128, 64])\n",
      "SegDecoder.4.scale.0 output shape: torch.Size([1, 384, 256, 128])\n",
      "\n",
      "Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.4.scale.1\n",
      "Input shape: torch.Size([1, 384, 256, 128])\n",
      "SegDecoder.4.scale.1 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "Sequential(\n",
      "  (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (1): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.4.scale\n",
      "Input shape: torch.Size([1, 384, 128, 64])\n",
      "SegDecoder.4.scale output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.4.block.0\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.block.0 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.4.block.1\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.block.1 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.4.block.2\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.block.2 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: SegDecoder.4.block.3\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.block.3 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: SegDecoder.4.block.4\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.block.4 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: SegDecoder.4.block\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.block output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: SegDecoder.4.relu\n",
      "Input shape: torch.Size([1, 64, 256, 128])\n",
      "SegDecoder.4.relu output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: SegDecoder.4\n",
      "Input shape: torch.Size([1, 384, 128, 64])\n",
      "SegDecoder.4 output shape: torch.Size([1, 64, 256, 128])\n",
      "\n",
      "Conv2d(84, 13, kernel_size=(1, 1), stride=(1, 1))\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: out_layer.scale\n",
      "Input shape: torch.Size([1, 84, 256, 128])\n",
      "out_layer.scale output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: out_layer.block.0\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.block.0 output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: out_layer.block.1\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.block.1 output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: out_layer.block.2\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.block.2 output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Module Name: out_layer.block.3\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.block.3 output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "Module Name: out_layer.block.4\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.block.4 output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Module Name: out_layer.block\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.block output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "ReLU(inplace=True)\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "Module Name: out_layer.relu\n",
      "Input shape: torch.Size([1, 13, 256, 128])\n",
      "out_layer.relu output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "ResBlock(\n",
      "  (scale): Conv2d(84, 13, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "<class '__main__.ResBlock'>\n",
      "Module Name: out_layer\n",
      "Input shape: torch.Size([1, 84, 256, 128])\n",
      "out_layer output shape: torch.Size([1, 13, 256, 128])\n",
      "\n",
      "ConditionGenerator(\n",
      "  (ClothEncoder): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (scale): Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (scale): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (scale): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (PoseEncoder): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (scale): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (scale): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (scale): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (scale): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv): ResBlock(\n",
      "    (scale): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (SegDecoder): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (scale): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (scale): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (1): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (scale): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (scale): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (scale): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (1): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (out_layer): ResBlock(\n",
      "    (scale): Conv2d(84, 13, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (flow_conv): ModuleList(\n",
      "    (0): Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(512, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "<class '__main__.ConditionGenerator'>\n",
      "Module Name: \n",
      "Input shape: torch.Size([1, 4, 256, 128])\n",
      " output 2 shape: torch.Size([1, 13, 256, 128])\n",
      " output 3 shape: torch.Size([1, 3, 256, 128])\n",
      " output 4 shape: torch.Size([1, 1, 256, 128])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_shape(module, input, output, name):\n",
    "    print(module)\n",
    "    print(type(module))\n",
    "    print(f\"Module Name: {name}\")\n",
    "    if len(input) == 1:\n",
    "        print('Input shape:', input[0].shape)\n",
    "    else:\n",
    "        print('Input shape:', input[1].shape)\n",
    "\n",
    "    # if isinstance(output, tuple):\n",
    "    #     for i, out in enumerate(output):\n",
    "    #         print(f'{name} output {i+1} shape:', out.shape)\n",
    "    # else:\n",
    "    #     print(f'{name} output shape:', output.shape)\n",
    "    # print()\n",
    "\n",
    "    if isinstance(output, tuple):\n",
    "        for i, out in enumerate(output):\n",
    "            if hasattr(out, 'shape'):\n",
    "                print(f'{name} output {i+1} shape:', out.shape)\n",
    "            # else:\n",
    "            #     print(f'{name} output {i+1}:', output)\n",
    "    elif isinstance(output, list):\n",
    "        for i, out in enumerate(output):\n",
    "            print(f'{name} output {i+1} shape:', out.shape)\n",
    "    else:\n",
    "        print(f'{name} output shape:', output.shape)\n",
    "    print()\n",
    "\n",
    "        \n",
    "    # print('Output shape:', output.shape)\n",
    "    # print()\n",
    "\n",
    "\n",
    "model = ConditionGenerator(opt, input1_nc, input2_nc, output_nc)\n",
    "for name, module in model.named_modules():\n",
    "    module.register_forward_hook(partial(print_shape, name=name))\n",
    "\n",
    "# Now when you run the forward pass, the shape of each intermediate tensor will be printed\n",
    "output = model(opt, input1, input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
